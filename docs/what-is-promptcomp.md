# What is PromptComp?

## The Core Insight

When you work with an LLM through a series of prompts, you're not just having a conversation--you're constructing a **derivation path** to a knowledge state. The sequence matters. The order matters. The specific framings you use matter.

PromptComp recognizes that these prompt sequences are a new form of prose: **executable writing** that encodes both the destination (the knowledge state) and the journey (how you got there).

## Knowledge States and Derivation Paths

Think of knowledge like a location in conceptual space. You can reach "understanding of recursive self-improvement in AI systems" through many routes:
- Start with basic recursion → add optimization → introduce AI → consider feedback loops
- Start with AI safety → add capability gains → introduce recursion → examine dynamics
- Start with biology/evolution → translate to computation → add intentionality → map to AI

Each path reaches similar conceptual territory, but the **derivation path** shapes what you see when you arrive. Different approaches highlight different aspects, foreground different concerns, establish different intuitions.

Traditional writing captures the destination. PromptComp captures the map.

## Why Prompts, Not Responses?

The AI responses are **projections** of the knowledge state--lossy representations rendered in a specific format at a specific moment. They're like photographs of a sculpture: useful, but not the sculpture itself.

Your prompts are the actual creative work. They're the questions that carved out the conceptual shape. They're the reframings that opened new dimensions. They're the examples that established boundaries.

**The prompts are canonical. Everything else is derivative.**

This is why PromptComp files contain only human inputs. The AI responses are reconstructable--any sufficiently capable LLM can regenerate them. But your specific sequence of prompts? That's irreplaceable.

## Executable Prose

A PromptComp isn't meant to be read like a traditional document. It's meant to be **executed**:

1. Open the `.promptcomp.md` file
2. Feed each prompt, in order, into an LLM
3. Observe the knowledge state emerge
4. Branch from any point to explore variations

This is writing as **performance instructions**, not as static text. Like musical notation or choreography, the score is not the performance--but it enables the performance to be reproduced.

## Projection vs. Flattening

Once you've stabilized a knowledge state through a PromptComp, you can **project** it into many forms:

- **Technical**: RFC, whitepaper, specification, architecture diagram
- **Narrative**: Short story, design fiction, incident report
- **Code**: Implementation, test suite, API documentation
- **Educational**: Tutorial, textbook chapter, ELI10 explanation
- **Critical**: Red team brief, ethical checklist, legal analysis
- **Creative**: Poetry, music, 3D world, interactive experience

Each projection is lossy--it emphasizes certain aspects and elides others. But because you have the canonical prompt sequence, you can always:

- Generate a different projection
- Modify the derivation path and re-project
- Branch to explore alternative framings
- Return to the source when projections conflict

Traditional writing forces you to commit to one projection. PromptComp keeps the source malleable.

## Why This is New

"But wait," you might object, "this is just conversation transcripts."

No. Three critical differences:

1. **Curation**: PromptComps extract the essential prompts from rambling conversations. Most chats contain false starts, tangents, clarifications--signal buried in noise. PromptComp distills to the derivation path.

2. **Intentionality**: PromptComps are created with awareness that the sequence itself is the artifact. They're crafted for replayability and branching, not just for getting an answer in the moment.

3. **Canonicality**: Traditional transcripts treat both sides equally. PromptComp recognizes that only the human inputs are irreplaceable--they're the actual creative contribution.

This isn't the first time a new medium has emerged from technological change:

- Writing → externalized memory
- Printing → mass distribution
- Hypertext → non-linear navigation
- Version control → collaborative evolution

PromptComp → **executable derivation paths**

## Multi-Modal Potential

Because knowledge states are abstract, they can project into any medium an LLM can work with:

- **Text**: Obviously
- **Code**: The knowledge state might be "algorithm for X"
- **Images**: Through AI image generation
- **Music**: Through algorithmic composition
- **3D worlds**: As scene descriptions or game mechanics
- **Dance**: As movement notation
- **Film**: As screenplay and shot descriptions

The same PromptComp could be:
- A technical paper (text projection)
- A working implementation (code projection)
- A visual explainer (diagram/animation projection)
- An interactive demo (web app projection)

Each projection serves different audiences and contexts, but all derive from the same canonical source.

## Comparison to Other Forms

| Form | Static? | Executable? | Captures Process? | Multi-format? |
|------|---------|-------------|-------------------|---------------|
| Essay | Yes | No | No | No |
| Code | Yes | Yes | Partial (git history) | No |
| Hypertext | Partial | No | No | Limited |
| API docs | Yes | Partial | No | No |
| PromptComp | No | Yes | Yes | Yes |

## What Makes a Good PromptComp?

Not every conversation is worth preserving as a PromptComp. Good candidates:

- **Reach a novel knowledge state**: You discovered something, connected ideas in a new way, or solved a problem through the conversation
- **Have a clear derivation path**: The sequence of prompts builds coherently toward the destination
- **Are replayable**: Someone else feeding in the same prompts would reach similar insights
- **Branch productively**: The knowledge state enables multiple useful projections
- **Crystallize cleanly**: The essential prompts can be extracted without losing coherence

Bad candidates:

- Requests for basic information
- Troubleshooting specific bugs
- One-off creative generations
- Conversations that dead-ended or changed direction multiple times without synthesis

## The Broader Vision

PromptComp is early-stage. Current limitations:

- Requires manual extraction (could be automated)
- No standard tooling for replay or projection
- No format for marking branch points or alternative paths
- No way to compose PromptComps into larger structures
- Limited ability to handle multi-modal inputs (images, documents)

But the core insight stands: **Human prompts are first-class artifacts that deserve preservation, sharing, and evolution.**

As LLMs become more capable and more ubiquitous, the ability to capture and transmit derivation paths becomes increasingly valuable. PromptComp is an early attempt to develop the literacy of this new medium.

## Further Reading

- [Creating a PromptComp](creating-a-promptcomp.md) - Practical how-to guide
- [Replaying a PromptComp](replaying-a-promptcomp.md) - Getting value from existing PromptComps
- [Blog entries](../blog/) - Examples of PromptComps in practice
